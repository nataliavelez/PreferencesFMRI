{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from os.path import join as opj\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: /scratch/groups/hyo/OPUS/BIDS_data\n",
      "Placing model specification in: /scratch/groups/hyo/OPUS/BIDS_data/derivatives/l1model\n"
     ]
    }
   ],
   "source": [
    "scratch_dir = os.environ['PI_SCRATCH']\n",
    "data_dir = opj(scratch_dir, 'OPUS', 'BIDS_data')\n",
    "model_dir = opj(data_dir, 'derivatives', 'l1model')\n",
    "\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "    \n",
    "print('Reading data from: %s' % data_dir)\n",
    "print('Placing model specification in: %s' % model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found subjects: ['sub-03', 'sub-04', 'sub-05', 'sub-06', 'sub-07', 'sub-08']\n"
     ]
    }
   ],
   "source": [
    "subjects = [os.path.basename(x) for x in glob.glob(opj(data_dir, 'sub-*'))]\n",
    "print('Found subjects: %s' % subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_names = ['self', 'motor-left', 'motor-right', 'self-chosen', 'self-unchosen']\n",
    "self_con = [\n",
    "    ('self: chosen > unchosen', 'T', self_names, [0, 0, 0, 1, -1]),\n",
    "    ('self: unchosen > chosen', 'T', self_names, [0, 0, 0, -1, 1]),\n",
    "    ('left > right', 'T', self_names, [0, 1, -1, 0, 0]),\n",
    "    ('right > left', 'T', self_names, [0, -1, 1, 0, 0]),\n",
    "    ('task', 'T', self_names, [1, 0, 0, 0, 0]),\n",
    "    ('rest', 'T', self_names, [-1, 0, 0, 0, 0])\n",
    "]\n",
    "\n",
    "self_con_out = opj(model_dir, 'task-self_model-value.json')\n",
    "with open(self_con_out, 'w') as fp:\n",
    "    json.dump(self_con, fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make event files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in subjects:\n",
    "    # Create subject directory\n",
    "    out_dir = opj(model_dir, sub, 'func')\n",
    "    if not os.path.isdir(out_dir):\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "    print('Saving model specification to: %s' % out_dir)\n",
    "\n",
    "    # Search for event files\n",
    "    sub_dir = opj(data_dir, sub, 'func')\n",
    "    event_files = glob.glob(opj(sub_dir, '*task-self*events.tsv'))\n",
    "    print('Found functional runs: %s' % event_files)\n",
    "\n",
    "    # Iterate over event files\n",
    "    for event_f in event_files:\n",
    "        events = pd.read_csv(event_f, sep='\\t')\n",
    "        \n",
    "        # Main effect of trial\n",
    "        trials = events.copy()[['onset', 'duration', 'trial_type']]\n",
    "\n",
    "        # Motor response\n",
    "        motor_response = pd.DataFrame()\n",
    "        motor_response['onset'] = events['onset'] + events['response_time']\n",
    "        motor_response['duration'] = 0.\n",
    "        motor_response['trial_type'] = ['motor-%s' % (d) for d in np.where(events.choice == 1, 'left', 'right')]\n",
    "        motor_response.dropna(inplace=True)\n",
    "\n",
    "        # Chosen value\n",
    "        chosen_value = trials.copy()\n",
    "        chosen_value['trial_type'] = 'self-chosen'\n",
    "        chosen_value['amplitude'] = events['self_value_c']\n",
    "        chosen_value.dropna(inplace=True)\n",
    "\n",
    "        # Unchosen value\n",
    "        unchosen_value = trials.copy()\n",
    "        unchosen_value['trial_type'] = 'self-unchosen'\n",
    "        unchosen_value['amplitude'] = np.where(events['choice'] == 1, events['self_value2'], events['self_value1'])\n",
    "        unchosen_value.dropna(inplace=True)\n",
    "\n",
    "        # Build model\n",
    "        model = pd.concat([trials, motor_response, chosen_value, unchosen_value])\n",
    "        model = model[['onset', 'duration', 'trial_type', 'amplitude']]\n",
    "        model.sort_values(axis=0, by=['onset', 'trial_type'], inplace=True)\n",
    "        model.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Save output\n",
    "        out_f = os.path.basename(event_f).replace('_run', '_model-value_run')\n",
    "        out_path = opj(out_dir, out_f)\n",
    "        model.to_csv(out_path, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = ['test', 'motor-left', 'motor-right', \n",
    "              'self-chosen', 'self-unchosen',\n",
    "              'other-chosen', 'other-unchosen']\n",
    "test_con = [\n",
    "    ('self: chosen > unchosen', 'T', test_names, [0, 0, 0, 1, -1, 0, 0]),\n",
    "    ('self: unchosen > chosen', 'T', test_names, [0, 0, 0, -1, 1, 0, 0]),\n",
    "    ('other: chosen > unchosen', 'T', test_names, [0, 0, 0, 0, 0, 1, -1]),\n",
    "    ('other: unchosen > chosen', 'T', test_names, [0, 0, 0, 0, 0, -1, 1]),\n",
    "    ('left > right', 'T', test_names, [0, 1, -1, 0, 0, 0, 0]),\n",
    "    ('right > left', 'T', test_names, [0, -1, 1, 0, 0, 0, 0]),\n",
    "    ('task', 'T', test_names, [1, 0, 0, 0, 0, 0, 0]),\n",
    "    ('rest', 'T', test_names, [-1, 0, 0, 0, 0, 0, 0])\n",
    "]\n",
    "\n",
    "test_con_out = opj(model_dir, 'task-test_model-value.json')\n",
    "with open(test_con_out, 'w') as fp:\n",
    "    json.dump(test_con, fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make event files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sub in subjects:\n",
    "sub = subjects[0] # Debug\n",
    "\n",
    "# Create subject directory\n",
    "out_dir = opj(model_dir, sub, 'func')\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "print('Saving model specification to: %s' % out_dir)\n",
    "\n",
    "# Search for event files\n",
    "sub_dir = opj(data_dir, sub, 'func')\n",
    "event_files = glob.glob(opj(sub_dir, '*task-test*events.tsv'))\n",
    "print('Found functional runs: %s' % event_files)\n",
    "\n",
    "# Iterate over event files\n",
    "#for event_f in event_files:\n",
    "event_f = event_files [0] # Debug\n",
    "print('Reading data from: %s' % event_f)\n",
    "events = pd.read_csv(event_f, sep='\\t')\n",
    "\n",
    "# Main effect of trial\n",
    "trials = events.copy()[['onset', 'duration', 'trial_type']]\n",
    "\n",
    "# Motor response\n",
    "motor_response = pd.DataFrame()\n",
    "motor_response['onset'] = events['onset'] + events['response_time']\n",
    "motor_response['duration'] = 0.\n",
    "motor_response['trial_type'] = ['motor-%s' % (d) for d in np.where(events.choice == 1, 'left', 'right')]\n",
    "motor_response.dropna(inplace=True)\n",
    "\n",
    "# Chosen value\n",
    "chosen_value = trials.copy()\n",
    "chosen_value['trial_type'] = 'self-chosen'\n",
    "chosen_value['amplitude'] = events['self_value_c']\n",
    "chosen_value.dropna(inplace=True)\n",
    "\n",
    "# Unchosen value\n",
    "unchosen_value = trials.copy()\n",
    "unchosen_value['trial_type'] = 'self-unchosen'\n",
    "unchosen_value['amplitude'] = np.where(events['choice'] == 1, events['self_value2'], events['self_value1'])\n",
    "unchosen_value.dropna(inplace=True)\n",
    "\n",
    "# Build model\n",
    "model = pd.concat([trials, motor_response, chosen_value, unchosen_value])\n",
    "model = model[['onset', 'duration', 'trial_type', 'amplitude']]\n",
    "model.sort_values(axis=0, by=['onset', 'trial_type'], inplace=True)\n",
    "model.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # Save output\n",
    "# out_f = os.path.basename(event_f).replace('_run', '_model-value_run')\n",
    "# out_path = opj(out_dir, out_f)\n",
    "# model.to_csv(out_path, sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make event files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make event files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neuro] *",
   "language": "python",
   "name": "conda-env-neuro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
